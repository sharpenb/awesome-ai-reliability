# Awesome ML Reliability üåü

![Awesome](https://awesome.re/badge.svg) ![MIT License](https://img.shields.io/badge/license-MIT-brightgreen)

A curated list of resources about Machine Learning (ML) reliability. It covers robustness, uncertainty, privacy, and trustworthiness of ML systems.

If you find this list helpful, give it a ‚≠ê on GitHub, share it, and feel free to contribute by submitting a pull request or issue!

## Tag Summary üé®

| Tag               | Description                                    | Badge Example                                          |
|-------------------|------------------------------------------------|-------------------------------------------------------|
| **Reliability**   | Focused on reliable ML systems                 | ![Reliability](https://img.shields.io/badge/Reliability-blue) |
| **Robustness**    | Ensuring robustness to various conditions      | ![Robustness](https://img.shields.io/badge/Robustness-green) |
| **Uncertainty**   | Quantifying and managing uncertainty           | ![Uncertainty](https://img.shields.io/badge/Uncertainty-orange) |
| **Ethics**        | Ethical considerations in ML                   | ![Ethics](https://img.shields.io/badge/Ethics-purple) |
| **Trustworthiness**| Building trustworthy AI systems               | ![Trustworthiness](https://img.shields.io/badge/Trustworthiness-red) |
| **Tools**         | Tools and frameworks for ML reliability        | ![Tools](https://img.shields.io/badge/Tools-cyan) |
| **Graph Learning**| Learning and robustness in graph-based models  | ![Graph Learning](https://img.shields.io/badge/Graph_Learning-teal) |
| **OOD Detection** | Detecting out-of-distribution samples          | ![OOD Detection](https://img.shields.io/badge/OOD_Detection-pink) |
| **Bayesian Methods** | Bayesian approaches to ML                   | ![Bayesian Methods](https://img.shields.io/badge/Bayesian_Methods-lime) |

---

## Facts/Numbers üìä
- **$1 Trillion**: Estimated annual global economic impact of unreliable AI systems ([Source](https://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/the-state-of-ai-in-2023)).
- **80%**: Percentage of ML projects that fail due to issues with data quality and system reliability ([Source](https://venturebeat.com/ai/mlops-failure-rates-in-machine-learning/)).
- **60%**: Increase in regulatory frameworks targeting AI reliability since 2020 ([Source](https://www2.deloitte.com/insights/us/en/focus/tech-trends/2023/ai-governance.html)).
- **3,000+**: Research papers on ML reliability published annually ([Source](https://www.semanticscholar.org/)).

---

## Tools üõ†Ô∏è
- **[TensorFlow Model Analysis](https://www.tensorflow.org/tfx/guide/tfma)**: Framework for evaluating model fairness, robustness, and reliability.
- **[Cleanlab](https://github.com/cleanlab/cleanlab)**: A Python library for finding and fixing label errors in datasets.
- **[Robustness Gym](https://robustnessgym.com/)**: Tools for testing model performance across diverse scenarios.
- **[DeepChecks](https://github.com/deepchecks/deepchecks)**: Comprehensive library for testing ML systems and datasets.

---

## Newspaper Articles üì∞
- *"The Dark Side of AI: How Reliability Issues Impact Society"* (2021) ![Robustness](https://img.shields.io/badge/Robustness-green) - [The New York Times](https://www.nytimes.com)
- *"Why Reliable AI is a Business Necessity"* (2022) ![Reliability](https://img.shields.io/badge/Reliability-blue) ![Business Impact](https://img.shields.io/badge/Business_Impact-orange) - [Forbes](https://www.forbes.com)
- *"Regulators are Closing In on AI Reliability"* (2023) ![Regulation](https://img.shields.io/badge/Regulation-red) ![Trustworthiness](https://img.shields.io/badge/Trustworthiness-purple) - [Financial Times](https://www.ft.com)

---

## Blog Articles üìù
- *"How to Build Reliable AI Systems"* (2020) ![Reliability](https://img.shields.io/badge/Reliability-blue) ![Practical Applications](https://img.shields.io/badge/Practical_Applications-orange) - [Towards Data Science](https://towardsdatascience.com)
- *"Reliability in Machine Learning: Lessons from Industry"* (2021) ![Industry Practices](https://img.shields.io/badge/Industry_Practices-lime) ![Trustworthiness](https://img.shields.io/badge/Trustworthiness-purple) - [Google AI Blog](https://ai.googleblog.com)
- *"Top 10 Tools for ML Reliability Testing"* (2022) ![Tools](https://img.shields.io/badge/Tools-cyan) ![Testing](https://img.shields.io/badge/Testing-teal) ![Robustness](https://img.shields.io/badge/Robustness-green) - [Analytics Vidhya](https://www.analyticsvidhya.com)

---

## Research Articles üìÑ
- *"Adversarial Robustness for Deep Learning"* (2019) [Robustness, Security] - [ArXiv](https://arxiv.org/abs/1905.01065)
- *"Fairness and Robustness in AI Systems"* (2020) [Fairness, Robustness, Ethics] - [Nature Machine Intelligence](https://www.nature.com/natmachintell)
- *"Uncertainty Quantification in ML"* (2021) [Uncertainty, Reliability] - [IEEE Transactions on Neural Networks and Learning Systems](https://ieeexplore.ieee.org)
- *"Exploring Bayesian Methods in Uncertainty Quantification"* (2021) [Uncertainty, Bayesian Methods] - [Proceedings of Machine Learning Research](https://proceedings.mlr.press)
- *"Energy-based Models for Out-of-Distribution Detection"* (2022) [Robustness, OOD Detection] - [NeurIPS](https://neurips.cc)
- *"Graph Neural Networks: Robustness Under Adversarial Settings"* (2022) [Graph Learning, Robustness] - [ICLR](https://iclr.cc)

---

## Books üìö
- *"Reliable Machine Learning"* (2020) [Reliability, Engineering] by Erik Jones
- *"Trustworthy AI"* (2021) [Ethics, Trustworthiness] by Beena Ammanath
- *"Robust Machine Learning in Python"* (2022) [Robustness, Tools] by Sarah Bird
- *"Uncertainty in Deep Learning: A Practical Guide"* (2023) [Uncertainty, Methods] by Yarin Gal
- *"Explainable AI and its Reliability"* (2022) [Explainability, Reliability] by Christoph Molnar

---

## Lectures üéì
- **"Reliability in AI: Challenges and Solutions"** [Reliability, Challenges] - [MIT OpenCourseWare](https://ocw.mit.edu)
- **"Robustness in Machine Learning"** [Robustness, Techniques] - [Stanford Online](https://online.stanford.edu)
- **"Trustworthy AI Systems"** [Trustworthiness, Systems] - [DeepMind YouTube](https://www.youtube.com)
- **"Uncertainty Estimation and Trust in ML"** [Uncertainty, Estimation] - [Cambridge University YouTube](https://www.youtube.com)

---

## People üßë‚Äçüíª
- **Bertrand Charpentier** - [Uncertainty, Bayesian Methods] Expert in Bayesian deep learning and uncertainty estimation.
- **Stephan G√ºnnemann** - [Robustness, Graph Learning] Expert in robust machine learning and uncertainty quantification.
- **Eyke H√ºllermeier** - [Uncertainty, Decision Theory] Leading researcher in uncertainty estimation and preference learning.
- **Eric Nalisnick** - [Uncertainty, Bayesian Methods] Specialist in Bayesian deep learning and uncertainty estimation.
- **Andrew Ng** - [Reliability, Education] Pioneer in ML reliability and online education.
- **Fei-Fei Li** - [Ethics, Reliability] Advocate for AI ethics and reliability.
- **Timnit Gebru** - [Fairness, Ethics] Renowned researcher in AI fairness and reliability.
- **Ian Goodfellow** - [Security, Adversarial Robustness] Expert on adversarial machine learning.
- **Yarin Gal** - [Uncertainty, Bayesian Methods] Thought leader in Bayesian deep learning and uncertainty estimation.
- **Zoubin Ghahramani** - [Bayesian Methods, Uncertainty] Leading expert in Bayesian machine learning and probabilistic models.
- **Balaji Lakshminarayanan** - [Uncertainty, Deep Ensembles] Prominent researcher in predictive uncertainty and reliability.
- **Dan Hendrycks** - [Robustness, OOD Detection] Expert in robustness to distribution shifts and adversarial attacks.
- **Alexander Amini** - [Uncertainty, Autonomous Systems] Researcher in evidential deep learning and uncertainty quantification for autonomous systems.
- **Dario Amodei** - [AI Safety, Alignment] Advocate for safe AI systems and robustness in large language models.
- **Nicholas Carlini** - [Security, Adversarial Attacks] Specialist in adversarial robustness and secure machine learning systems.
- **Chelsea Finn** - [Robustness, Generalization] Researcher in meta-learning, reliability, and generalization in robotics and ML.
- **Samy Bengio** - [Uncertainty, Generative Models] Expert in reliability and robustness in generative machine learning systems.
- **Jascha Sohl-Dickstein** - [Robustness, Generative Methods] Researcher in reliable generative models and diffusion-based techniques.
- **Karen Simonyan** - [Vision, Robustness] Key researcher in robust deep learning for computer vision applications.
- **Christian Szegedy** - [Adversarial Robustness, Vision] Expert on robustness in image recognition and adversarial example defenses.
- **Nick Bostrom** - [AI Safety, Ethics] Author of *Superintelligence*, emphasizing reliability in AI systems and societal impacts.
- **Marta Kwiatkowska** - [AI Safety, Formal Verification] Researcher in formal methods for AI reliability and safety.
- **Ryan Adams** - [Bayesian Methods, Uncertainty] Researcher in scalable Bayesian inference and uncertainty quantification.
- **Katherine Heller** - [Uncertainty, Bayesian Inference] Specialist in Bayesian methods for reliable probabilistic modeling.
- **Chris Olah** - [Interpretability, Robustness] Advocate for interpretability and reliability in deep neural networks.
- **Arvind Narayanan** - [Fairness, Security] Researcher focusing on fairness, privacy, and secure ML systems.
- **Joan Bruna** - [Graph Learning, Robustness] Researcher in robust and reliable graph neural networks.
- **Percy Liang** - [Uncertainty, Reliability] Prominent researcher in generalization and robustness of machine learning models.
- **Shakir Mohamed** - [Ethics, Reliability] Advocate for equitable and reliable AI systems, focusing on fairness and interpretability.
- **Michael Jordan** - [Statistics, Reliability] Pioneer in probabilistic machine learning and reliable AI models.
- **Geoffrey Hinton** - [Neural Networks, Interpretability] Foundational researcher in neural network reliability and robustness.
- **Max Welling** - [Bayesian Methods, Deep Learning] Expert in uncertainty quantification and scalable Bayesian methods.
- **Vladimir Vapnik** - [Generalization, Reliability] Developer of support vector machines and theories on generalization.
- **Leslie Kaelbling** - [Reinforcement Learning, Robustness] Prominent researcher in reliable reinforcement learning.
- **Pieter Abbeel** - [Robotics, Robustness] Leader in reliable robotic learning and real-world ML applications.
- **Sanja Fidler** - [Vision, Robustness] Expert in robust computer vision and safety in ML applications.
- **Thomas Dietterich** - [Fairness, Safety] Researcher focusing on fairness, reliability, and safety in ML.
- **Hanna Wallach** - [Fairness, Ethics] Researcher on societal impacts and fairness in machine learning.
- **Anca Dragan** - [Human-AI Interaction, Safety] Advocate for reliable human-AI collaboration and interaction.
- **David Silver** - [Reinforcement Learning, Reliability] Developer of AlphaGo and reliability in RL systems.
- **Oriol Vinyals** - [Reinforcement Learning, Robustness] Expert in multi-agent systems and reinforcement learning reliability.
- **Kevin Murphy** - [Uncertainty, Probabilistic Models] Leading researcher in probabilistic models for reliable AI.
- **Cynthia Rudin** - [Interpretability, Ethics] Advocate for interpretable and responsible AI systems.
- **Pushmeet Kohli** - [Robustness, Verification] Specialist in verifying the robustness of machine learning models.
- **Jonas Peters** - [Causality, Reliability] Expert in causal inference and robust machine learning.
- **Adrian Weller** - [Fairness, Explainability] Researcher in fairness and reliable explainability methods.

---

## Contributing ü§ù
We welcome contributions! Please follow our [contribution guidelines](CONTRIBUTING.md) to share resources, tools, or ideas that align with the theme of ML reliability.

---

## License üìÑ
This project is licensed under the [MIT License](LICENSE). Feel free to share and use the resources as needed.

---
