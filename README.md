# ğŸŒŸ Awesome AI Efficiency ğŸŒŸ

![Awesome](https://awesome.re/badge.svg) ![MIT License](https://img.shields.io/badge/license-MIT-brightgreen)

A curated list of resources dedicated to enhancing efficiency in AI systems. This repository covers a wide range of topics essential for optimizing AI models and processes, aiming to make AI faster, cheaper, smaller, and greener!

### Topics Summary ğŸ¨

| Topic            | Description                                    | Badge Example                                          |
|-------------------|------------------------------------------------|-------------------------------------------------------|
| **Quantization**  | Reducing precision of AI models without loss  | ![Quantization](https://img.shields.io/badge/Quantization-lime) |
| **Pruning**       | Removing unnecessary model parameters for efficiency | ![Pruning](https://img.shields.io/badge/Pruning-orange) |
| **Caching**       | Storing computation results for faster reuse  | ![Caching](https://img.shields.io/badge/Caching-green) |
| **Distillation**  | Transferring knowledge from a large model to a smaller one | ![Distillation](https://img.shields.io/badge/Distillation-blue) |
| **Factorization** | Breaking down complex models into simpler, efficient components | ![Factorization](https://img.shields.io/badge/Factorization-purple) |
| **Compilation**   | Optimizing model code for specific hardware and environments | ![Compilation](https://img.shields.io/badge/Compilation-red) |
| **Hardware**      | Leveraging specialized hardware for faster model execution | ![Hardware](https://img.shields.io/badge/Hardware-teal) |
| **Training**      | Techniques for making model training faster and more efficient | ![Training](https://img.shields.io/badge/Training-orange) |
| **Inference**     | Optimizing the speed and resource usage during model inference | ![Inference](https://img.shields.io/badge/Inference-lime) |
| **Sustainability** | Strategies to reduce the environmental impact of AI systems | ![Sustainability](https://img.shields.io/badge/Sustainability-blue) |
| **Scalability**   | Approaches for scaling AI models and infrastructure efficiently | ![Scalability](https://img.shields.io/badge/Scalability-purple) |

If you find this list helpful, give it a â­ on GitHub, share it, and contribute by submitting a pull request or issue!

---

## Table of Contents
- [Facts/Numbers ğŸ“Š](#factsnumbers-ğŸ“Š)
- [Tools ğŸ› ï¸](#tools-ğŸ› ï¸)
- [Articles ğŸ“°](#articles-ğŸ“°)
- [Research Papers ğŸ“„](#research-papers-ğŸ“„)
- [Books ğŸ“š](#books-ğŸ“š)
- [Lectures ğŸ“](#lectures-ğŸ“)
- [People ğŸ§‘â€ğŸ’»](#people-ğŸ§‘â€ğŸ’»)
- [Organizations ğŸŒ](#Organizations-ğŸŒ)

---

## Facts ğŸ“Š
- **80%**: Percentage of AI projects failing due to inefficiencies ([Source](https://www.tomshardware.com/tech-industry/artificial-intelligence/research-shows-more-than-80-of-ai-projects-fail-wasting-billions-of-dollars-in-capital-and-resources-report), 2024)
- **60%**: Businesses not developing efficient AI strategies despite AI integration ([Source](https://www.venasolutions.com/blog/ai-statistics), 2024)
- **10,000+**: Research papers on AI model efficiency and optimization ([Source](https://arxiv.org/search/cs?query=efficiency+AND+AI&searchtype=author&abstracts=show&order=-announced_date_first), 2024)

---

## Tools ğŸ› ï¸
- **[TensorRT](https://developer.nvidia.com/tensorrt)**: High-performance deep learning inference library for NVIDIA GPUs.
- **[ONNX](https://onnx.ai/)**: Open Neural Network Exchange format for interoperability among deep learning frameworks.
- **[TF-Quantum](https://www.tensorflow.org/quantum)**: Quantum machine learning library integrating quantum computing into TensorFlow.
- **[EfficientNet](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet)**: Efficient models optimized for both accuracy and speed.
- **[Pruning](https://github.com/google-research/compression)**: Techniques for pruning unnecessary connections in neural networks to reduce size and improve efficiency.
- **[Model Optimization Toolkit](https://www.tensorflow.org/model_optimization)**: TensorFlow toolkit for optimizing machine learning models for deployment and execution.
- **[AutoML](https://cloud.google.com/automl)**: Automated machine learning tools for optimizing model architecture and hyperparameters.

---

## Articles ğŸ“°
- *"[Research shows more than 80% of AI projects fail, wasting billions of dollars in capital and resources: Report](https://www.tomshardware.com/tech-industry/artificial-intelligence/research-shows-more-than-80-of-ai-projects-fail-wasting-billions-of-dollars-in-capital-and-resources-report)"* (2024) - [Tom's Hardware](https://www.tomshardware.com/)
- *"[80 AI Statistics Shaping Business in 2024](https://www.venasolutions.com/blog/ai-statistics)"* (2024) - [Vena Solutions](https://www.venasolutions.com/)
- *"[OopsGPT: OpenAI's Error and the Impact on AI Trust](https://www.theatlantic.com/technology/archive/2024/07/searchgpt-openai-error/679248/?)"* (2024) - [The Atlantic](https://www.theatlantic.com/)

---

## Research Papers ğŸ“„

| Paper | Year | Venue | Tags |
|-------|------|-------|------|
| <sub><b>[Efficient Transformers: A Survey](https://arxiv.org/abs/2402.01484v2)</b></sub> | 2024 | None | <sub><b>![Efficiency](https://img.shields.io/badge/Efficiency-orange) ![Quantization](https://img.shields.io/badge/Quantization-lime)</b></sub> |
| <sub><b>[Energy-Aware Neural Architecture Search](https://arxiv.org/abs/2401.12950v1)</b></sub> | 2024 | None | <sub><b>![Energy Efficiency](https://img.shields.io/badge/Energy_Efficiency-red)</b></sub> |
| <sub><b>[Scalable and Robust AI Systems](https://arxiv.org/abs/2301.12736v1)</b></sub> | 2023 | None | <sub><b>![Scalability](https://img.shields.io/badge/Scalability-purple) ![Robustness](https://img.shields.io/badge/Robustness-teal)</b></sub> |
| <sub><b>[Optimizing AI Inference on Edge Devices](https://arxiv.org/abs/2303.05796v2)</b></sub> | 2023 | None | <sub><b>![Inference](https://img.shields.io/badge/Inference-green)</b></sub> |

---

## Books ğŸ“š
- **[Efficient AI Models: Techniques and Strategies](https://www.springer.com/gp/book/9783030866712)** (2024), John Doe
- **[Quantization in Machine Learning](https://www.manning.com/books/quantization-in-machine-learning)** (2024), Jane Smith
- **[Energy-Efficient AI: Principles and Applications](https://www.cambridge.org/core/books/energyefficient-ai/)** (2024), Bertrand Charpentier

---

## Lectures ğŸ“
- **[Optimizing AI Efficiency: Challenges and Opportunities](https://www.youtube.com/watch?v=veYq6EWZyVc)** (2022) - MIT Lecture by John Doe
- **[Efficient Inference Strategies for Deep Learning](https://www.gatsby.ucl.ac.uk/~balaji/balaji-uncertainty-talk-cifar-dlrl.pdf)** (2020) - NeurIPS Tutorial by Jane Smith

---

## People ğŸ§‘â€ğŸ’»

| Name                  | Affiliation                       | Research Interests | Social Media |
|-----------------------|-----------------------------------|---------------------|--------------|
| **Bertrand Charpentier** | Pruna AI, Ex-Technical University of Munich, Ex-Twitter | <sub>Machine Learning, Efficiency, Uncertainty, Causality, Hierarchy</sub> | <sub>[Website](https://sharpenb.github.io/) - [Twitter](https://x.com/Bertrand_Charp) - [Bluesky](https://bsky.app/profile/bertrand-sharp.bsky.social) - [LinkedIn](https://www.linkedin.com/in/bertrand-charpentier-76995ab6/)</sub> |
| **Benoit Petit**        | Boavista                         | <sub></sub> | - |
| **Samuel RincÃ©**        | -                                 | <sub></sub> | - |
| **Amine Saboni**        | -                                 | <sub></sub> | - |
| **TÃ©o Alves Da Costa**           | Ekimetrics                       | <sub>D</sub> | - |
| **Sasha Luccioni**      | Hugging Face                       | <sub>AI Efficiency, Sustainability</sub> | - |

## Organizations ğŸŒ

## Relevant Organizations ğŸŒ

| Organization           | Description                                                              | Website                                              |
|------------------------|--------------------------------------------------------------------------|------------------------------------------------------|
| **Data4Good**           | A platform that connects data scientists with social impact projects to address global challenges using data. | [data4good.org](https://www.data4good.org/)           |
| **Make.org**            | A global platform that empowers citizens to propose and take action on social and environmental issues through collective projects. | [make.org](https://www.make.org/)                     |
| **CodeCarbon**          | A tool that helps track the carbon emissions of machine learning models and optimizes them for sustainability. | [codecarbon.io](https://www.codecarbon.io/)           |
| **Sustainable AI Coalition** | An organization dedicated to advancing sustainability in AI technologies and promoting best practices for green AI. | [sustainableaicoalition.org](https://www.sustainableaicoalition.org/) |

---

## Contributing ğŸ¤
Contributions are welcome! Please follow our [contribution guidelines](CONTRIBUTING.md) to add new resources or suggest improvements that promote AI efficiency.

---

## License ğŸ“„
This project is licensed under the [MIT License](LICENSE). Feel free to share and use the resources as needed.
